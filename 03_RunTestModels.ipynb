{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24fa99f3",
   "metadata": {},
   "source": [
    "## 2.0 Test the machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d4e9b",
   "metadata": {},
   "source": [
    "Here we collect some images that were never used for training and/or validation of the machine learning models. We process those images using\n",
    "1. Noise reduction model: To reduce overall noise in the image\n",
    "2. Super-resolution model: To increase the pixel count per unit area by 4X\n",
    "The result of the noise reduction model is fed as an input to the super-resolution model\n",
    "Finally, we reduce the super resolved image to its original size using cubic-spline interpolation. This down-sampling further increases the signal to noise ratio (40% for every 2X down-sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import skimage.io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb84b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NR = load_model(\"D:\\\\myData\\\\ML_Quality\\\\autoencoder_NR.h5\")\n",
    "model_SR = load_model(\"D:\\\\myData\\\\ML_Quality\\\\super_resolution_SR.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b02e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataPath = \"D:\\\\myData\\\\ML_Quality\\\\x_test\\\\*.tif\"\n",
    "result_path = \"D:\\\\myData\\\\ML_Quality\\\\x_test\\\\ML_NRSR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da3755",
   "metadata": {},
   "source": [
    "The code below is writte inside a for loop so that multiple images are read and tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(test_dataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa986d3d",
   "metadata": {},
   "source": [
    "#### 2.1 Process the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d8eb10",
   "metadata": {},
   "source": [
    "Here we implemented three similar functions. \n",
    "First one, uses only noise reduction model and demonstrates the effect of this model on a given image.\n",
    "Second one, uses the super resolution model and scales the image 4X without blurring the image and with additional enhancements to contrast, etc. as learned by training process\n",
    "In the third implementation we concatenated noise reduction and super resolution processes to take advantage of multiple models to improve the image quality.\n",
    "Finally we bring the super resolved image back to original image size using cubic spline down-sampling there by further increasing the signal to noise ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d432e80a",
   "metadata": {},
   "source": [
    "#### Only noise reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ff3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:   \n",
    "    x_NR_test=[] # list to hold input image\n",
    "    #read the image file\n",
    "    img = skimage.io.imread(file)      \n",
    "    img = np.array(img)\n",
    "    \n",
    "    dim=img.shape # used to down size the image back to original size after super-resolution\n",
    "    \n",
    "    #pad the image to reduce boundary issues\n",
    "    pad = 32\n",
    "    img = np.pad(img, pad, mode=\"reflect\")\n",
    "    x_NR_test.append(img)\n",
    "    \n",
    "    ## do the necessary input data shape adjustments 9as required by tensorflow)\n",
    "    x_NR_test = np.dstack(x_NR_test)\n",
    "    x_NR_test = np.rollaxis(x_NR_test,-1)\n",
    "    x_NR_test = x_NR_test[:,:,:, tf.newaxis]\n",
    "    \n",
    "    # do the noise reduction using NR model\n",
    "    NR_predict = model_NR(x_NR_test)\n",
    "    \n",
    "    #use the noise reduced image to build super-resolution image\n",
    "    img = predictions[0]\n",
    "    img = img[:, :, 0] # back to 2D, 1 channel image\n",
    "    img = img[pad:-pad, pad:-pad] # unpad the image\n",
    "    \n",
    "    # byte scale the image (0-255)\n",
    "    img = (255*(img-np.min(img))/(np.max(img) - np.min(img)))\n",
    "    \n",
    "    #write the output\n",
    "    skimage.io.imsave(result_path+\"\\\\NR_\"+os.path.basename(file), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f80c0e",
   "metadata": {},
   "source": [
    "#### Only super-resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:   \n",
    "    x_NR_test=[] # list to hold input image\n",
    "    #read the image file\n",
    "    img = skimage.io.imread(file)      \n",
    "    img = np.array(img)\n",
    "    \n",
    "    dim=img.shape # used to down size the image back to original size after super-resolution\n",
    "    \n",
    "    #pad the image to reduce boundary issues\n",
    "    pad = 32\n",
    "    img = np.pad(img, pad, mode=\"reflect\")\n",
    "    x_SR_test.append(img)\n",
    "    \n",
    "    ## do the necessary input data shape adjustments 9as required by tensorflow)\n",
    "    x_SR_test = np.dstack(x_SR_test)\n",
    "    x_SR_test = np.rollaxis(x_SR_test,-1)\n",
    "    x_SR_test = x_SR_test[:,:,:, tf.newaxis]\n",
    "    \n",
    "    #do the super-resolution using SR model\n",
    "    SR_predict = model_SR(x_SR_test)\n",
    "    \n",
    "    # write the image output\n",
    "    img = predictions[0]\n",
    "    img = img[:, :, 0]\n",
    "    \n",
    "    # resize the image to original image dimensions\n",
    "    img = cv2.resize(img, dim, interpolation=cv2.INTER_CUBIC) \n",
    "    \n",
    "    #byte scale the image (0-255)\n",
    "    img = (255*(img-np.min(img))/(np.max(img) - np.min(img)))\n",
    "    \n",
    "    #write the output\n",
    "    skimage.io.imsave(result_path+\"\\\\SR_\"+os.path.basename(file), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c849b1",
   "metadata": {},
   "source": [
    "### Concatenating Noise Reduction and Super Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43484c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:   \n",
    "    x_NR_test=[] # list to hold input image\n",
    "    #read the image file\n",
    "    img = skimage.io.imread(file)      \n",
    "    img = np.array(img)\n",
    "    \n",
    "    dim=img.shape # used to down size the image back to original size after super-resolution\n",
    "    \n",
    "    #pad the image to reduce boundary issues\n",
    "    pad = 32\n",
    "    img = np.pad(img, pad, mode=\"reflect\")\n",
    "    x_NR_test.append(img)\n",
    "    \n",
    "    ## do the necessary input data shape adjustments 9as required by tensorflow)\n",
    "    x_NR_test = np.dstack(x_NR_test)\n",
    "    x_NR_test = np.rollaxis(x_NR_test,-1)\n",
    "    x_NR_test = x_NR_test[:,:,:, tf.newaxis]\n",
    "    \n",
    "    # do the noise reduction using NR model\n",
    "    NR_predict = model_NR(x_NR_test)\n",
    "    \n",
    "    #use the noise reduced image to build super-resolution image\n",
    "    img = predictions[0]\n",
    "    img = img[:, :, 0] # back to 2D, 1 channel image\n",
    "    img = img[pad:-pad, pad:-pad] # unpad the image\n",
    "    \n",
    "    # byte scale the image (0-255)\n",
    "    img = (255*(img-np.min(img))/(np.max(img) - np.min(img)))\n",
    "    \n",
    "    # append the image to super resolution input list\n",
    "    x_SR_test.append(img)\n",
    "    \n",
    "    # do the necessary list shape adjustments required for tensorflow\n",
    "    x_SR_test = np.dstack(x_SR_test)\n",
    "    x_SR_test = np.rollaxis(x_SR_test,-1)\n",
    "    x_SR_test = x_SR_test[:,:,:, tf.newaxis]\n",
    "    \n",
    "    #do the super-resolution using SR model\n",
    "    SR_predict = model_SR(x_SR_test)\n",
    "    \n",
    "    # write the image output\n",
    "    img = predictions[0]\n",
    "    img = img[:, :, 0]\n",
    "    \n",
    "    # resize the image to original image dimensions\n",
    "    img = cv2.resize(img, dim, interpolation=cv2.INTER_CUBIC) \n",
    "    \n",
    "    #byte scale the image (0-255)\n",
    "    img = (255*(img-np.min(img))/(np.max(img) - np.min(img)))\n",
    "    \n",
    "    #write the output\n",
    "    skimage.io.imsave(result_path+\"\\\\\"+os.path.basename(file), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125a130c",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efcd81d",
   "metadata": {},
   "source": [
    "The above code reads images from a given folder, sets-up image into a appropriate dimension list (as required by tensorflow) and uses\n",
    "1. Noise Reduction model (model_NR) to reduce the noise in the image using U-net based noise reduction technique\n",
    "2. Super Resolution model (model_SR) to increase the X and Y dimensions of the image by 4X without blurring the image\n",
    "In the final processing stage, we down-sample the super-resolved image to its original size (i.e. 4X down-sampling). This improves the signal to noise ratio substantially (40% for every 2X down-sizing) and in the end has not changed image dimensions but significantly improved image quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8ee4c",
   "metadata": {},
   "source": [
    "### Results of image enhancement using individual models and the concatenation is shown in the final report. Model description and preliminary conclusions on the results is also reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd703d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
